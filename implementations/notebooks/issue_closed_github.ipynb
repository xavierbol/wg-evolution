{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython2",
  "version": 2
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Issues Closed\n",
    "This is the reference implementation for [Issues Closed](https://github.com/chaoss/wg-evolution/blob/master/metrics/Issues_Closed.md),\n",
    "a metric specified by the\n",
    "[Evolution Working Group](https://github.com/chaoss/wg-evolution) of the\n",
    "[CHAOSS project](https://chaoss.community).\n",
    "This implementation is specific to Git repositories.\n",
    "\n",
    "Have a look at [README.md](../README.md) to find out how to run this notebook (and others in this directory) as well as to get a better understanding of the purpose of the implementations.\n",
    "\n",
    "The implementation is described in two parts (see below):\n",
    "\n",
    "* Class for computing Issues Closed\n",
    "* An explanatory analysis of the class' functionality\n",
    "\n",
    "Some more auxiliary information in this notebook:\n",
    "\n",
    "* Examples of the use of the implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "As discussed in the [README](../README.md) file, the scripts required to analyze the data fetched by Perceval are located in the `code_df` package. Due to python's import system, to import modules from a package which is not in the current directory, we have to either add the package to `PYTHONPATH` or simply append a `../..` to `sys.path`, so that `code_df` can be successfully imported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from implementations.scripts.issue_github import IssueGithub \n",
    "from implementations.scripts.utils import read_json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IssueClosedGithub(IssueGithub):\n",
    "    \"\"\"\n",
    "    Issues Closed metric\n",
    "    \"\"\"\n",
    "    def compute(self):\n",
    "        closed_issues = [item['hash'] for item in self.items if item['current_status'] == 'closed']\n",
    "        return len(closed_issues)\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Issues Closed'"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performing the Analysis\n",
    "Using the above class, we can perform several kinds of analysis on the JSON data file, fetched by Perceval.\n",
    "\n",
    "For starters, we can perform a simple count of the number of issues closed in the data. For this analysis, we can vary the value passed to the `date_range` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Counting the total number of commits \n",
    "We first read the JSON file containing Perceval data using the `read_json_file` utility function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = read_json_file('../issues_events.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's use the `compute` method to count the total number of issues closed. First, we will do it without passing any since and until dates. \n",
    "Next, we can pass in the start and end dates as a tuple. The format would be `%Y-%m-%d`.\n",
    "\n",
    "A third kind of analysis we can perform is passing only one of the dates to `date_range` --- either `since` or `until`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = IssuesClosedGitHub(items)\n",
    "print(\"The total number of issues closed \"\n",
    "      \"is {}.\".format(issues.compute()))\n",
    "\n",
    "date_since = datetime.strptime(\"2018-01-01\", \"%Y-%m-%d\")\n",
    "date_until = datetime.strptime(\"2019-07-01\", \"%Y-%m-%d\")    \n",
    "\n",
    "issues_dated = IssuesClosedGitHub(items,\n",
    "                        date_range=(date_since, date_until))\n",
    "                        \n",
    "print(\"The total number of issues closed between \"\n",
    "      \"2018-01-01 and 2019-07-01 is {}.\".format(issues_dated.compute()))\n",
    "\n",
    "issues_after = IssuesClosedGitHub(items,\n",
    "                        date_range=(date_since, None))\n",
    "                        \n",
    "print(\"The total number of issues closed after \"\n",
    "      \"2018-01-01 is {}.\".format(issues_after.compute()))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reopen as New\n",
    "When this parameter is `True`, every time an issue is reopened, it is treated as a new issue. From the creation of the issue to the first closing event is considered as a separate issue. After that, every reopening creates a new issue. Finally, the original issue which we considered is removed, since it is now redundant.\n",
    "\n",
    "To use this, simply pass `True` for this parameter in the class' `__init__` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}